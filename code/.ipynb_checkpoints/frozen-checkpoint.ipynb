{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import hiive.mdptoolbox as mdptoolbox\n",
    "from hiive.mdptoolbox.mdp import ValueIteration, PolicyIteration, QLearning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    b'S': 'b',\n",
    "    b'F': 'w',\n",
    "    b'H': 'k',\n",
    "    b'G': 'g'\n",
    "}\n",
    "\n",
    "directions = {\n",
    "            0: '←',\n",
    "            1: '↓',\n",
    "            2: '→',\n",
    "            3: '↑'\n",
    "}\n",
    "\n",
    "def plot_lake(env, policy=None, title='Frozen Lake'):\n",
    "    squares = env.nrow\n",
    "    fig = plt.figure(figsize=(6, 6 + 0.01*squares))\n",
    "    ax = fig.add_subplot(111, xlim=(0, squares), ylim=(0, squares))\n",
    "    plt.title(title, fontsize=16, weight='bold', y=1.01)\n",
    "    for i in range(squares):\n",
    "        for j in range(squares):\n",
    "            y = squares - i - 1\n",
    "            x = j\n",
    "            p = plt.Rectangle([x, y], 1, 1, linewidth=1, edgecolor='k')\n",
    "            p.set_facecolor(colors[env.desc[i,j]])\n",
    "            ax.add_patch(p)\n",
    "            \n",
    "            if policy is not None:\n",
    "                text = ax.text(x+0.5, y+0.5, directions[policy[i, j]],\n",
    "                               weight='bold', \n",
    "                               horizontalalignment='center', verticalalignment='center',\n",
    "                               color='w')\n",
    "                text.set_path_effects([path_effects.Stroke(linewidth=2, foreground='black'),\n",
    "                                       path_effects.Normal()])\n",
    "            \n",
    "    plt.axis('off')\n",
    "    plt.savefig('./figures/frozen/' + title + '.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on:\n",
    "# https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438\n",
    "def get_score(env, policy, episodes=1000):\n",
    "  misses = 0\n",
    "  steps_list = []\n",
    "  for episode in range(episodes):\n",
    "    observation = env.reset()\n",
    "    steps=0\n",
    "    while True:\n",
    "      \n",
    "      action = policy[observation]\n",
    "      observation, reward, done, _ = env.step(action)\n",
    "      steps+=1\n",
    "      if done and reward == 1:\n",
    "        # print('You have got the fucking Frisbee after {} steps'.format(steps))\n",
    "        steps_list.append(steps)\n",
    "        break\n",
    "      elif done and reward == 0:\n",
    "        # print(\"You fell in a hole!\")\n",
    "        misses += 1\n",
    "        break\n",
    "  print('----------------------------------------------')\n",
    "  print('You took an average of {:.0f} steps to get the frisbee'.format(np.mean(steps_list)))\n",
    "  print('And you fell in the hole {:.2f} % of the times'.format((misses/episodes) * 100))\n",
    "  print('----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on:\n",
    "# https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438\n",
    "def get_policy(env,stateValue, lmbda=0.9):\n",
    "  policy = [0 for i in range(env.nS)]\n",
    "  for state in range(env.nS):\n",
    "    action_values = []\n",
    "    for action in range(env.nA):\n",
    "      action_value = 0\n",
    "      for i in range(len(env.P[state][action])):\n",
    "        prob, next_state, r, _ = env.P[state][action][i]\n",
    "        action_value += prob * (r + lmbda * stateValue[next_state])\n",
    "      action_values.append(action_value)\n",
    "    best_action = np.argmax(np.asarray(action_values))\n",
    "    policy[state] = best_action\n",
    "  return policy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAFsCAYAAABvrmq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAK/klEQVR4nO3db6hteV3H8c93usw5MzoSOvaHzAyGSnIqMCGKKUQLqcx6EhaRkhMOUWQUPSihCQIrJwJBSs00chiCGKW0YAgKRh9YYlAgJBJTJCOOpTNZ3pvj/fVg7+PsDuecO5f2fO713tcLFnftvdZe81uLc9/7d9c+58ystQJAxw1XegAA1xPRBSgSXYAi0QUoEl2AItEFKBLd68DM3D0z64zlnVd6jC0zc9vOeX9sT8d86c4xX7+PY3LtEl2AItG9/vz6WmuOLa++1Itm5rAwNrjmiS7/x8y8a+efyt81M/fPzKNJ/nFnn++ZmffOzKdm5vMz8/DM3DczL9jZ59wlbmn8wc6+z5yZe2bmozNzfmYem5m/mZmXHxvbnTuvf83MvGFm/m1mPjszH5iZF+75Wrx1Zj48M49sz/OxmfngzLx2ZuYSr71pZv56Z7yv29n2nTPznpn55Mz8z8x8fGb+cGaeu8/xc5Vaa1mu8SXJ3UnWdrn7Evu+a2ffT+2sf2y7/VVJLu48v7t8Lskd2/3OnbLP0fK27X5fleSfz9jvF3bGdufO858+Yd9HktxyifO77fg5nbHv42eM61d39nvpzvOvT3KY5IHt44tJ7trZ98fPOO4jSW670l8vlqd2MdO9/vzaCbPOHz5l388k+Y4kNyf5oZm5JcmbkkySzyd5RZJnJPnZ7f6HSd6SJGutx9fOLYwk35RNVI6O+6bt+m8k+fpsQvQjSW5K8rVJPrDd/oaZ+YoTxnYxyXcnuTXJg9vnbk3ysid/KS7pVdlE+pYkB0m+NcnD222vO2W2e2OS+5N873aMr1lr/X6SzMzTk7w5yZcl+VCSb9ge9yXZXM9bk/z2HsfPVejclR4AV7VfWWt9cLv+kZn5/mwimyR/vtb6s+36m2fmriQvSPL8mXneWuuho4PMzHOymfk9O5vZ8MvXWke3K45uIZxL8u4TxnCQTVz/9Njzb1trPbg9/v1J7tg+/3WXf5qnWknekeT2bM57d5Jya5JnJvn3Y6/5xWzepB5P8pNrrft2tt2R5Mu369+e5KMn/De/7/8/bK5mZrrXn5M+SHvPKfv+/bHHz95Z/9dj2/5lZ/2LM9OZeVY2wX1uNiH60bXW+0855mmedcJz/7Sz/l8763v5wG9mfiLJvXkilCf9XbnphOdu3v756SR/e2zbSTP24542MwdPdpx86RFdzvK5Y48f2Vk//qHP7uNPJl/85/RfJnl+NrPGO9da7z3lmI8lufH4G0KSG9ZabzlhbJ/fWX8qfj/pK3fWfybJ4XY8/3CJ1z2Y5AvZvJn81XaWf+STO+u/d8Kb39H5XtjHCXB1El0ux4NJHt2u/+DM/MDMPH17a+H27fMfWWs9NDM3ZnO74EXb5395rfVHJxzzKMLPSPLWmXnOzNw8M988M69N8uGn6FyS5OaZedkJy9OzmZUfeTTJDTNzZ5JvucQxH0jy09v152UT3qPZ/PvzxPX7qZl55fb6PXv7nSL3JPmdvZwZVy33dHnS1lr/OTM/n819zhvzRDCPnE9y13b9jmw+1T/yxpl5487jt6+17szm0/6XZHMv9tXbZdcX9jL4k311NjPx427P5g3jFdvH927//O8kH0/yNWcddK31ju2Hf7+Z5BuTPDAzL15rfWZmfi7JO7O5V33fCS9/++WeBF9azHS5LNvZ6ouTvC/Jf2QzI/xEkj9J8qKjD7ey+Q6HJ3O8h5O8MMk92dynvZDks9v1e5P82D7H/2Rtz/OXkjyUzZvJ32XznREPPcnX/1aemLV+W5K/mJmnrbX+OJsPBt+dze2Gx7d/fiibSP/u3k6Cq9Ks5X/XA9BipgtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARWf+GPDMTZ9Izn9lazDXuoODw4sXLpz3Rrcnh4eHF8+fdz33wbXcr+0vLzrRmT+RNjPrqfkFTteriZ8A3J8Z13NfXMu9OzW63tkAikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYrOnbXx4ODw4oULI8x7NDNXegjXjIODA9dzj1zL/Vlrnbptztw4s87azuXxRb1/vj73w9fmfq21Tr2gZrEARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUCS6AEWiC1AkugBFogtQJLoARaILUHTurI2Hh4cXZ0aY9+Tw8DDnz5+/0sO4ZhweHmZmrvQw4LLMWuv0jTPrrO1cnpmJ67k/ruf+ePPar7XWqRfULBagSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBis5dYvvFmRHmPTk4OMjMXOlhXDMODw9dz305l+TxKz2I68Oloiu4e3ThwoWsta70MK4ZM+N67snMJHdf6VFcH0QVoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpEF6BIdAGKRBegSHQBikQXoEh0AYpmrXWlxwBw3TDTBSgSXYAi0QUoEl2AItEFKBJdgKL/Bcv9G3S8hWscAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x434.88 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup 4x4\n",
    "env = gym.make('FrozenLake-v0').unwrapped\n",
    "\n",
    "# Create transition and reward matrices\n",
    "rows = env.nrow\n",
    "cols = env.ncol\n",
    "T = np.zeros((4, rows*cols, rows*cols))\n",
    "R = np.zeros((4, rows*cols, rows*cols))\n",
    "\n",
    "old_state = np.inf\n",
    "\n",
    "for square in env.P:\n",
    "    for action in env.P[square]:\n",
    "        for i in range(len(env.P[square][action])):\n",
    "            new_state = env.P[square][action][i][1]\n",
    "            if new_state == old_state:\n",
    "                T[action][square][env.P[square][action][i][1]] = T[action][square][old_state] + env.P[square][action][i][0]\n",
    "                R[action][square][env.P[square][action][i][1]] = R[action][square][old_state] + env.P[square][action][i][2]\n",
    "            else:\n",
    "                T[action][square][env.P[square][action][i][1]] = env.P[square][action][i][0]\n",
    "                R[action][square][env.P[square][action][i][1]] = env.P[square][action][i][2]\n",
    "            old_state = env.P[square][action][i][1]\n",
    "            \n",
    "#print(T)\n",
    "#print(R)\n",
    "plot_lake(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0)\n",
      "[[0 3 0 3]\n",
      " [0 0 0 0]\n",
      " [3 1 0 0]\n",
      " [0 2 1 0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-da0d9be5325d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplot_lake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-802216a0f894>\u001b[0m in \u001b[0;36mplot_lake\u001b[0;34m(env, policy, title)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 text = ax.text(x+0.5, y+0.5, directions[policy[i, j]],\n\u001b[0;32m---> 30\u001b[0;31m                                \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                                \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverticalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                color='w')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_size' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x434.88 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ValueIteration(T, R, gamma=0.9, max_iter=1000, epsilon=1e-3)\n",
    "\n",
    "run = test.run()\n",
    "time = run[-1]['Time']\n",
    "iterations = run[-1]['Iteration']\n",
    "reward = run[-1]['Max V']\n",
    "\n",
    "print(test.policy)\n",
    "\n",
    "policy = np.array(test.policy)\n",
    "policy = policy.reshape(4,4)\n",
    "print(policy)\n",
    "\n",
    "plot_lake(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vi(env, T, R, gammas, epsilons=[1e-4], max_iter=10000):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 0.56\n"
     ]
    }
   ],
   "source": [
    "# code based on:\n",
    "# https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438\n",
    "def value_iteration(env, max_iterations=1000, lmbda=0.9):\n",
    "    t0 = time()\n",
    "    \n",
    "    stateValue = [0 for i in range(env.nS)]\n",
    "    newStateValue = stateValue.copy()\n",
    "    for iter in range(max_iterations):\n",
    "        for state in range(env.nS):\n",
    "            action_values = []      \n",
    "            for action in range(env.nA):\n",
    "                state_value = 0\n",
    "                for i in range(len(env.P[state][action])):\n",
    "                    prob, next_state, reward, done = env.P[state][action][i]\n",
    "                    state_action_value = prob * (reward + lmbda*stateValue[next_state])\n",
    "                    state_value += state_action_value\n",
    "                action_values.append(state_value)      #the value of each action\n",
    "                best_action = np.argmax(np.asarray(action_values))   # choose the action which gives the maximum value\n",
    "                newStateValue[state] = action_values[best_action]  #update the value of the state\n",
    "        if i > 10: \n",
    "            diff = abs(sum(stateValue) - sum(newStateValue))\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            display(iter, diff)\n",
    "            \n",
    "            if diff < 1e-04:   # if there is negligible difference break the loop\n",
    "                break\n",
    "                print(i)\n",
    "        else:\n",
    "            stateValue = newStateValue.copy()\n",
    "            \n",
    "    total_time = time() - t0\n",
    "    print('Total Time: %.2f' % total_time)\n",
    "    \n",
    "    return stateValue \n",
    "\n",
    "Us = value_iteration(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(env, max_iterations=100000, lmbda=0.9):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Us = value_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = get_policy(env, Us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
