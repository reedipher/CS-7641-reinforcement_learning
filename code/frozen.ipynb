{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import hiive.mdptoolbox as mdptoolbox\n",
    "from hiive.mdptoolbox.mdp import ValueIteration, PolicyIteration, QLearning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# suppress pandas warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    b'S': 'b',\n",
    "    b'F': 'w',\n",
    "    b'H': 'k',\n",
    "    b'G': 'g'\n",
    "}\n",
    "\n",
    "directions = {\n",
    "            0: '←',\n",
    "            1: '↓',\n",
    "            2: '→',\n",
    "            3: '↑'\n",
    "}\n",
    "\n",
    "def plot_lake(env, policy=None, title='Frozen Lake'):\n",
    "    squares = env.nrow\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, xlim=(-.01, squares+0.01), ylim=(-.01, squares+0.01))\n",
    "    plt.title(title, fontsize=16, weight='bold', y=1.01)\n",
    "    for i in range(squares):\n",
    "        for j in range(squares):\n",
    "            y = squares - i - 1\n",
    "            x = j\n",
    "            p = plt.Rectangle([x, y], 1, 1, linewidth=1, edgecolor='k')\n",
    "            p.set_facecolor(colors[env.desc[i,j]])\n",
    "            ax.add_patch(p)\n",
    "            \n",
    "            if policy is not None:\n",
    "                text = ax.text(x+0.5, y+0.5, directions[policy[i, j]],\n",
    "                               horizontalalignment='center', size=25, verticalalignment='center',\n",
    "                               color='k')\n",
    "            \n",
    "    plt.axis('off')\n",
    "    plt.savefig('./figures/frozen/' + title + '.png')\n",
    "    \n",
    "#plot_lake(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on:\n",
    "# https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438\n",
    "def get_score(env, policy, episodes=1000):\n",
    "    misses = 0\n",
    "    steps_list = []\n",
    "    for episode in range(episodes):\n",
    "        observation = env.reset()\n",
    "        steps=0\n",
    "        while True:\n",
    "            action = policy[observation]\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            steps+=1\n",
    "            if done and reward == 1:\n",
    "                # print('You have got the Frisbee after {} steps'.format(steps))\n",
    "                steps_list.append(steps)\n",
    "                break\n",
    "            elif done and reward == 0:\n",
    "                # print(\"You fell in a hole!\")\n",
    "                misses += 1\n",
    "                break\n",
    "    print('----------------------------------------------')\n",
    "    ave_steps = np.mean(steps_list)\n",
    "    pct_fail  = (misses/episodes)* 100\n",
    "    print('You took an average of {:.0f} steps to get the frisbee'.format(ave_steps))\n",
    "    print('And you fell in the hole {:.2f} % of the times'.format(pct_fail))\n",
    "    print('----------------------------------------------')\n",
    "  \n",
    "    return ave_steps, pct_fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on:\n",
    "# https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438\n",
    "def get_policy(env,stateValue, lmbda=0.9):\n",
    "    policy = [0 for i in range(env.nS)]\n",
    "    for state in range(env.nS):\n",
    "        action_values = []\n",
    "        for action in range(env.nA):\n",
    "            action_value = 0\n",
    "            for i in range(len(env.P[state][action])):\n",
    "                prob, next_state, r, _ = env.P[state][action][i]\n",
    "                action_value += prob * (r + lmbda * stateValue[next_state])\n",
    "            action_values.append(action_value)\n",
    "        best_action = np.argmax(np.asarray(action_values))\n",
    "        policy[state] = best_action\n",
    "    return policy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup 4x4\n",
    "env = gym.make('FrozenLake-v0').unwrapped\n",
    "\n",
    "# Create transition and reward matrices from OpenAI P matrix\n",
    "rows = env.nrow\n",
    "cols = env.ncol\n",
    "T = np.zeros((4, rows*cols, rows*cols))\n",
    "R = np.zeros((4, rows*cols, rows*cols))\n",
    "\n",
    "old_state = np.inf\n",
    "\n",
    "for square in env.P:\n",
    "    for action in env.P[square]:\n",
    "        for i in range(len(env.P[square][action])):\n",
    "            new_state = env.P[square][action][i][1]\n",
    "            if new_state == old_state:\n",
    "                T[action][square][env.P[square][action][i][1]] = T[action][square][old_state] + env.P[square][action][i][0]\n",
    "                R[action][square][env.P[square][action][i][1]] = R[action][square][old_state] + env.P[square][action][i][2]\n",
    "            else:\n",
    "                T[action][square][env.P[square][action][i][1]] = env.P[square][action][i][0]\n",
    "                R[action][square][env.P[square][action][i][1]] = env.P[square][action][i][2]\n",
    "            old_state = env.P[square][action][i][1]\n",
    "            \n",
    "#print(T)\n",
    "#print(R)\n",
    "plot_lake(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueIteration(t, r, gammas, epsilons, plot=False, max_iterations=100000):\n",
    "    # create data structure to save off\n",
    "    columns = ['gamma', 'epsilon', 'time', 'iterations', 'reward', 'mean_rewards', 'max_rewards', 'error', 'policy', 'average_steps', 'success_pct']\n",
    "    data = pd.DataFrame(0.0, index=np.arange(len(gammas)*len(epsilons)), columns=columns)\n",
    "    \n",
    "    print('Gamma,\\tEps,\\tTime,\\tIter,\\tReward')\n",
    "    print(80*'_')\n",
    "    \n",
    "    testNum = 0\n",
    "    for g in gammas:\n",
    "        for e in epsilons:\n",
    "            test = ValueIteration(t, r, gamma=g, max_iter=10000, epsilon=e)\n",
    "            \n",
    "            runs  = test.run()\n",
    "            time  = runs[-1]['Time']\n",
    "            iters = runs[-1]['Iteration']\n",
    "            maxR  = runs[-1]['Max V']\n",
    "            \n",
    "            max_rewards, mean_rewards, errors = [], [], []\n",
    "            for run in runs:\n",
    "                max_rewards.append(run['Max V'])\n",
    "                mean_rewards.append(run['Mean V'])\n",
    "                errors.append(run['Error'])\n",
    "            \n",
    "            policy = np.array(test.policy)\n",
    "            policy = policy.reshape(4,4)\n",
    "            \n",
    "            data['gamma'][testNum]        = g\n",
    "            data['epsilon'][testNum]      = e\n",
    "            data['time'][testNum]         = time\n",
    "            data['iterations'][testNum]   = iters\n",
    "            data['reward'][testNum]       = maxR\n",
    "            data['mean_rewards'][testNum] = {tuple(mean_rewards)}\n",
    "            data['max_rewards'][testNum]  = {tuple(max_rewards)}\n",
    "            data['error'][testNum]        = {tuple(errors)}\n",
    "            data['policy'][testNum]       = {test.policy}\n",
    "            \n",
    "            print('%.2f,\\t%.0E,\\t%.2f,\\t%d,\\t%f' % (g, e, time, iters, maxR))\n",
    "            \n",
    "            if plot:\n",
    "                title = 'FrozenLake_' + str(rows) + 'x' + str(cols) + '_g' + str(g) + '_e' + str(e)\n",
    "                plot_lake(env, policy, title)\n",
    "            \n",
    "            testNum = testNum + 1\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma,\tEps,\tTime,\tIter,\tReward\n",
      "________________________________________________________________________________\n",
      "0.30,\t1E-04,\t0.00,\t6,\t0.375077\n",
      "0.30,\t1E-08,\t0.00,\t13,\t0.375103\n",
      "0.30,\t1E-12,\t0.00,\t20,\t0.375103\n",
      "0.60,\t1E-04,\t0.00,\t13,\t0.447623\n",
      "0.60,\t1E-08,\t0.00,\t29,\t0.447649\n",
      "0.60,\t1E-12,\t0.00,\t46,\t0.447649\n",
      "0.90,\t1E-04,\t0.00,\t60,\t0.639007\n",
      "0.90,\t1E-08,\t0.01,\t128,\t0.639020\n",
      "0.90,\t1E-12,\t0.01,\t195,\t0.639020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>time</th>\n",
       "      <th>iterations</th>\n",
       "      <th>reward</th>\n",
       "      <th>mean_rewards</th>\n",
       "      <th>max_rewards</th>\n",
       "      <th>error</th>\n",
       "      <th>policy</th>\n",
       "      <th>average_steps</th>\n",
       "      <th>success_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.375077</td>\n",
       "      <td>{(0.020833333333333332, 0.02708333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.36666666666666664, 0.3...</td>\n",
       "      <td>{(0.3333333333333333, 0.03333333333333333, 0.0...</td>\n",
       "      <td>{(1, 2, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>{(0.020833333333333332, 0.02708333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.36666666666666664, 0.3...</td>\n",
       "      <td>{(0.3333333333333333, 0.03333333333333333, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>{(0.020833333333333332, 0.02708333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.36666666666666664, 0.3...</td>\n",
       "      <td>{(0.3333333333333333, 0.03333333333333333, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.447623</td>\n",
       "      <td>{(0.020833333333333332, 0.03333333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.39999999999999997, 0.4...</td>\n",
       "      <td>{(0.3333333333333333, 0.06666666666666667, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.447649</td>\n",
       "      <td>{(0.020833333333333332, 0.03333333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.39999999999999997, 0.4...</td>\n",
       "      <td>{(0.3333333333333333, 0.06666666666666667, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.447649</td>\n",
       "      <td>{(0.020833333333333332, 0.03333333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.39999999999999997, 0.4...</td>\n",
       "      <td>{(0.3333333333333333, 0.06666666666666667, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.639007</td>\n",
       "      <td>{(0.020833333333333332, 0.03958333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.4333333333333333, 0.49...</td>\n",
       "      <td>{(0.3333333333333333, 0.09999999999999999, 0.0...</td>\n",
       "      <td>{(0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.639020</td>\n",
       "      <td>{(0.020833333333333332, 0.03958333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.4333333333333333, 0.49...</td>\n",
       "      <td>{(0.3333333333333333, 0.09999999999999999, 0.0...</td>\n",
       "      <td>{(0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>0.012506</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.639020</td>\n",
       "      <td>{(0.020833333333333332, 0.03958333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.4333333333333333, 0.49...</td>\n",
       "      <td>{(0.3333333333333333, 0.09999999999999999, 0.0...</td>\n",
       "      <td>{(0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma       epsilon      time  iterations    reward  \\\n",
       "0    0.3  1.000000e-04  0.000607         6.0  0.375077   \n",
       "1    0.3  1.000000e-08  0.001071        13.0  0.375103   \n",
       "2    0.3  1.000000e-12  0.002968        20.0  0.375103   \n",
       "3    0.6  1.000000e-04  0.001431        13.0  0.447623   \n",
       "4    0.6  1.000000e-08  0.003019        29.0  0.447649   \n",
       "5    0.6  1.000000e-12  0.003978        46.0  0.447649   \n",
       "6    0.9  1.000000e-04  0.003905        60.0  0.639007   \n",
       "7    0.9  1.000000e-08  0.008844       128.0  0.639020   \n",
       "8    0.9  1.000000e-12  0.012506       195.0  0.639020   \n",
       "\n",
       "                                        mean_rewards  \\\n",
       "0  {(0.020833333333333332, 0.02708333333333333, 0...   \n",
       "1  {(0.020833333333333332, 0.02708333333333333, 0...   \n",
       "2  {(0.020833333333333332, 0.02708333333333333, 0...   \n",
       "3  {(0.020833333333333332, 0.03333333333333333, 0...   \n",
       "4  {(0.020833333333333332, 0.03333333333333333, 0...   \n",
       "5  {(0.020833333333333332, 0.03333333333333333, 0...   \n",
       "6  {(0.020833333333333332, 0.03958333333333333, 0...   \n",
       "7  {(0.020833333333333332, 0.03958333333333333, 0...   \n",
       "8  {(0.020833333333333332, 0.03958333333333333, 0...   \n",
       "\n",
       "                                         max_rewards  \\\n",
       "0  {(0.3333333333333333, 0.36666666666666664, 0.3...   \n",
       "1  {(0.3333333333333333, 0.36666666666666664, 0.3...   \n",
       "2  {(0.3333333333333333, 0.36666666666666664, 0.3...   \n",
       "3  {(0.3333333333333333, 0.39999999999999997, 0.4...   \n",
       "4  {(0.3333333333333333, 0.39999999999999997, 0.4...   \n",
       "5  {(0.3333333333333333, 0.39999999999999997, 0.4...   \n",
       "6  {(0.3333333333333333, 0.4333333333333333, 0.49...   \n",
       "7  {(0.3333333333333333, 0.4333333333333333, 0.49...   \n",
       "8  {(0.3333333333333333, 0.4333333333333333, 0.49...   \n",
       "\n",
       "                                               error  \\\n",
       "0  {(0.3333333333333333, 0.03333333333333333, 0.0...   \n",
       "1  {(0.3333333333333333, 0.03333333333333333, 0.0...   \n",
       "2  {(0.3333333333333333, 0.03333333333333333, 0.0...   \n",
       "3  {(0.3333333333333333, 0.06666666666666667, 0.0...   \n",
       "4  {(0.3333333333333333, 0.06666666666666667, 0.0...   \n",
       "5  {(0.3333333333333333, 0.06666666666666667, 0.0...   \n",
       "6  {(0.3333333333333333, 0.09999999999999999, 0.0...   \n",
       "7  {(0.3333333333333333, 0.09999999999999999, 0.0...   \n",
       "8  {(0.3333333333333333, 0.09999999999999999, 0.0...   \n",
       "\n",
       "                                              policy  average_steps  \\\n",
       "0  {(1, 2, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "1  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "2  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "3  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "4  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "5  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "6  {(0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "7  {(0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "8  {(0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...            0.0   \n",
       "\n",
       "   success_pct  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "5          0.0  \n",
       "6          0.0  \n",
       "7          0.0  \n",
       "8          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas   = [0.3, 0.6, 0.9]\n",
    "epsilons = [1e-4, 1e-8, 1e-12]\n",
    "vi_data  = valueIteration(T, R, gammas, epsilons, plot=False)\n",
    "\n",
    "vi_data.head(len(gammas)*len(epsilons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "You took an average of 20 steps to get the frisbee\n",
      "And you fell in the hole 78.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 31 steps to get the frisbee\n",
      "And you fell in the hole 54.10 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 28 steps to get the frisbee\n",
      "And you fell in the hole 59.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 30 steps to get the frisbee\n",
      "And you fell in the hole 54.30 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 30 steps to get the frisbee\n",
      "And you fell in the hole 54.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 27 steps to get the frisbee\n",
      "And you fell in the hole 55.40 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 43 steps to get the frisbee\n",
      "And you fell in the hole 20.40 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 44 steps to get the frisbee\n",
      "And you fell in the hole 22.60 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of 45 steps to get the frisbee\n",
      "And you fell in the hole 22.60 % of the times\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>time</th>\n",
       "      <th>iterations</th>\n",
       "      <th>reward</th>\n",
       "      <th>mean_rewards</th>\n",
       "      <th>max_rewards</th>\n",
       "      <th>error</th>\n",
       "      <th>policy</th>\n",
       "      <th>average_steps</th>\n",
       "      <th>success_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.375077</td>\n",
       "      <td>{(0.020833333333333332, 0.02708333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.36666666666666664, 0.3...</td>\n",
       "      <td>{(0.3333333333333333, 0.03333333333333333, 0.0...</td>\n",
       "      <td>{(1, 2, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>20.231818</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>{(0.020833333333333332, 0.02708333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.36666666666666664, 0.3...</td>\n",
       "      <td>{(0.3333333333333333, 0.03333333333333333, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>30.501089</td>\n",
       "      <td>45.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>{(0.020833333333333332, 0.02708333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.36666666666666664, 0.3...</td>\n",
       "      <td>{(0.3333333333333333, 0.03333333333333333, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>27.675610</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.447623</td>\n",
       "      <td>{(0.020833333333333332, 0.03333333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.39999999999999997, 0.4...</td>\n",
       "      <td>{(0.3333333333333333, 0.06666666666666667, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>30.052516</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.447649</td>\n",
       "      <td>{(0.020833333333333332, 0.03333333333333333, 0...</td>\n",
       "      <td>{(0.3333333333333333, 0.39999999999999997, 0.4...</td>\n",
       "      <td>{(0.3333333333333333, 0.06666666666666667, 0.0...</td>\n",
       "      <td>{(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...</td>\n",
       "      <td>29.902174</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma       epsilon      time  iterations    reward  \\\n",
       "0    0.3  1.000000e-04  0.000607         6.0  0.375077   \n",
       "1    0.3  1.000000e-08  0.001071        13.0  0.375103   \n",
       "2    0.3  1.000000e-12  0.002968        20.0  0.375103   \n",
       "3    0.6  1.000000e-04  0.001431        13.0  0.447623   \n",
       "4    0.6  1.000000e-08  0.003019        29.0  0.447649   \n",
       "\n",
       "                                        mean_rewards  \\\n",
       "0  {(0.020833333333333332, 0.02708333333333333, 0...   \n",
       "1  {(0.020833333333333332, 0.02708333333333333, 0...   \n",
       "2  {(0.020833333333333332, 0.02708333333333333, 0...   \n",
       "3  {(0.020833333333333332, 0.03333333333333333, 0...   \n",
       "4  {(0.020833333333333332, 0.03333333333333333, 0...   \n",
       "\n",
       "                                         max_rewards  \\\n",
       "0  {(0.3333333333333333, 0.36666666666666664, 0.3...   \n",
       "1  {(0.3333333333333333, 0.36666666666666664, 0.3...   \n",
       "2  {(0.3333333333333333, 0.36666666666666664, 0.3...   \n",
       "3  {(0.3333333333333333, 0.39999999999999997, 0.4...   \n",
       "4  {(0.3333333333333333, 0.39999999999999997, 0.4...   \n",
       "\n",
       "                                               error  \\\n",
       "0  {(0.3333333333333333, 0.03333333333333333, 0.0...   \n",
       "1  {(0.3333333333333333, 0.03333333333333333, 0.0...   \n",
       "2  {(0.3333333333333333, 0.03333333333333333, 0.0...   \n",
       "3  {(0.3333333333333333, 0.06666666666666667, 0.0...   \n",
       "4  {(0.3333333333333333, 0.06666666666666667, 0.0...   \n",
       "\n",
       "                                              policy  average_steps  \\\n",
       "0  {(1, 2, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...      20.231818   \n",
       "1  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...      30.501089   \n",
       "2  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...      27.675610   \n",
       "3  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...      30.052516   \n",
       "4  {(1, 3, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1,...      29.902174   \n",
       "\n",
       "   success_pct  \n",
       "0         22.0  \n",
       "1         45.9  \n",
       "2         41.0  \n",
       "3         45.7  \n",
       "4         46.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See differences in policy\n",
    "policies = vi_data['policy']\n",
    "\n",
    "for i,p in enumerate(policies):\n",
    "    pol = list(p)[0]\n",
    "    steps, failures = get_score(env, pol)\n",
    "    vi_data['average_steps'][i] = steps\n",
    "    vi_data['success_pct'][i] = 100-failures\n",
    "    \n",
    "vi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Steps')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare number of iterations with lowest epsilon\n",
    "x = gammas\n",
    "y = vi_data.loc[vi_data['epsilon'] == min(epsilons)]['average_steps']\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig=plt.figure()\n",
    "\n",
    "ax = sns.barplot(x, y)\n",
    "ax.set_title('Number of Iterations vs. Gamma')\n",
    "ax.set_xlabel('Gamma')\n",
    "ax.set_ylabel('Average Steps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    41.0\n",
       "5    44.6\n",
       "8    77.4\n",
       "Name: success_pct, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare success of runs\n",
    "x = gammas\n",
    "y = vi_data.loc[vi_data['epsilon'] == min(epsilons)]['success_pct']\n",
    "\n",
    "fig=plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(env, max_iterations=100000, lmbda=0.9):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Us = value_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = get_policy(env, Us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
